{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6830b4d-cd2e-4547-b2ba-7c0192ee941a",
   "metadata": {},
   "source": [
    "# Parler-TTS Mini v0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b6ae0b-6f2f-4451-a6d7-7b9022815d4c",
   "metadata": {},
   "source": [
    "Generate high-quality, natural sounding speech with a text prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4687ec-c508-4a07-bd02-14f7c7d7d626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!pip3 install -q git+https://github.com/huggingface/parler-tts.git gradio spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f2a116-525a-4d8c-a1c0-2f0a86fd3554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import torch\n",
    "from parler_tts import ParlerTTSForConditionalGeneration\n",
    "from transformers import AutoTokenizer, AutoFeatureExtractor\n",
    "import gradio as gr\n",
    "import spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f28c35-1b51-4dc5-acfd-359b221d878e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167c02c6-c2f4-477a-a544-79bf276e93cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check device\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974fdda5-c34d-41fe-99c6-c9e57edacbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "model_name = \"parler-tts/parler_tts_mini_v0.1\"\n",
    "model = ParlerTTSForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf05638-70ab-44e3-b320-dbcde6ebb5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract model sampling rate\n",
    "sr = feature_extractor.sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b50fac-1e7d-41d7-a814-b89d04946a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set example text prompts and descriptions\n",
    "examples = [\n",
    "    [\n",
    "        \"Hey, how are you doing today?\",\n",
    "        \"A female speaker with a slightly high-pitched voice delivers her words quite expressively, in a very confined sounding environment with clear audio quality. She speaks very fast.\"\n",
    "    ],\n",
    "    [\n",
    "        \"The life of the land is perpetuated in righteousness.\",\n",
    "        \"A male speaker with a low-pitched voice delivers his words at a slightly slow pace and a dramatic tone, in a very spacious environment, accompanied by noticeable background noise.\"\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cee278e-1a3c-4d86-b340-133fb1acfea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to generate speech with a text prompt\n",
    "@spaces.GPU # ZeroGPU\n",
    "def generate_speech(text, description):\n",
    "    \"\"\"\n",
    "    Generate speech with a text prompt.\n",
    "    \"\"\"\n",
    "    input_ids = tokenizer(description, return_tensors=\"pt\").input_ids.to(device)\n",
    "    prompt_input_ids = tokenizer(text, return_tensors=\"pt\").input_ids.to(device)\n",
    "    \n",
    "    generation = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        prompt_input_ids=prompt_input_ids,\n",
    "        do_sample=True,\n",
    "        temperature=1.0\n",
    "    )\n",
    "    audio_arr = generation.cpu().numpy().squeeze()\n",
    "    \n",
    "    return sr, audio_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a863999e-23a7-4e42-8219-c139aadd89ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Gradio application\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Parler-TTS Mini\")\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        Tips:\n",
    "        - Include term \"very clear audio\" and/or \"very noisy audio\"\n",
    "        - Use punctuation for prosody\n",
    "        - Control gender, speaking rate, pitch, reverberation in prompt\n",
    "        \"\"\"\n",
    "    )\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            input_text = gr.Textbox(\n",
    "                label=\"Input Text\",\n",
    "                lines=2,\n",
    "                elem_id=\"input_text\"\n",
    "            )\n",
    "            description = gr.Textbox(\n",
    "                label=\"Description\",\n",
    "                lines=2,\n",
    "                elem_id=\"input_description\"\n",
    "            )\n",
    "            run_button = gr.Button(\"Generate Audio\", variant=\"primary\")\n",
    "        with gr.Column():\n",
    "            audio_out = gr.Audio(\n",
    "                label=\"Parler-TTS generation\",\n",
    "                type=\"numpy\",\n",
    "                elem_id=\"audio_out\"\n",
    "            )\n",
    "    \n",
    "    inputs = [input_text, description]\n",
    "    outputs = [audio_out]\n",
    "    gr.Examples(\n",
    "        examples=examples,\n",
    "        fn=generate_speech,\n",
    "        inputs=inputs,\n",
    "        outputs=outputs,\n",
    "        cache_examples=True\n",
    "    )\n",
    "    run_button.click(\n",
    "        fn=generate_speech,\n",
    "        inputs=inputs,\n",
    "        outputs=outputs,\n",
    "        queue=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e1a36c-66c1-47c9-ab45-3738ca085ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set queue with default settings\n",
    "demo.queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef17835-cda7-4879-a3f7-be2c776dae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Gradio application\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a413fac8-1703-451b-b22d-d659bcd88dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close Gradio application\n",
    "demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efda6a60-9492-40fe-a30f-286bb8b4c11b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
